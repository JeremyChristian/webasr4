{% extends 'rest_framework/api.html' %} 
{% block content %}
{% load static %}
<div class="well">

	<h1>Supporting Projects</h1>


    <a href="http://www.amiproject.org" target="_new" border="0"><img src="{% static "frontend/ami_consortium.gif" %}" align="right"></a>
    <h2>AMIDA: Augmented Multi-party Interaction with Distance Access</h2>

    <p>AMIDA is a European Commissioned project that will understand better, and build new support for, human communication at a distance.

    <p>The ground-breaking research that we shall undertake in AMIDA will span several traditionally separate disciplines, including:
    <ul>
      <li>Qualitative human analysis and human factors;
      <li>Audio-video processing, including unconstrained speech recognition and natural scene analysis;
      <li>Multimodal structure and content analysis, including the modelling of individuals and groups, through the joint processing of multiple (multimodal) information channels (audio, visual, slides, handwriting, and white board activity);
      <li>HCI, application prototyping, evaluation, and system integration.
    </ul>

    <p>The AMIDA research work will directly build upon the recognized achievements and large multimodal corpora (becoming a standard reference in the area of multimodal processing) resulting from AMI.

    <p>AMIDA represents a very challenging shift in emphasis from meeting recordings to live meetings with remote participants, using affordable commodity sensors (such as webcams and cheaper microphones), and targeting the development of advanced videoconferencing systems featuring new functionalities such as (1) filtering, searching and browsing; (2) remote monitoring; (3) interactive accelerated playback; (4) meeting support; and (5) shared context and presence.

    <p>While addressing additional scientific challenges (such as real-time processing and processing of lower quality audio and visual signals), AMIDA also raises the transfer potential of technologies through genuine integration of the AMIDA industrial partners collaborating on common prototypes and applications. Finally, through its Community of Interest, the AMI Consortium will also actively engage beyond the consortium members to spread awareness and knowledge among vendors, futurists and other research laboratories in the field.
     <p>

    <h2>NST: Natural Speech Technology</h2>
        <a href="http://n-s-t.org" target="_new" border="0"><img src="{% static "frontend/nst.gif" %}" align="right" width="200px" ></a>


    <p>Natural Speech Technology (NST) is an EPSRC Programme Grant with the aim of significantly advancing the state-of-the-art in speech technology by making it more natural, approaching human levels of reliability, adaptability and conversational richness. NST is a collaboration between the Centre for Speech Technology Research (CSTR) at the University of Edinburgh, the Speech Group at the University of Cambridge and The Speech and Hearing Research Group (SpandH), University of Sheffield.
    

	
</div>

{% endblock %}